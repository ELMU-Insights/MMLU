# ðŸ“Š Zero-Shot Prompting Evaluation Results (MMLU Law Enforcement)

This document summarizes the zero-shot evaluation results of various language models, including **ELMU Insights**, **ChatGPT**, and **Claude**, on the MMLU Law Enforcement dataset.

---

## ðŸ§ª Evaluation Summary

| Model Run | Language | Date | Total Questions | Errors Detected | Correct Responses | Accuracy (%) |
|-----------|----------|------|------------------|------------------|-------------------|---------------|
| ELMU Insights | English | 7-May-2025 | 29 | 10 | 19 | 65.5% |
| ELMU Insights | English | 20-May-2025 | 100 | 14 | 86 | 86.0% |
| ELMU Insights | Bahasa Melayu | 25-June-2025 | 100 | 3 | 97 | 97.0% |
| ELMU Insights | English | 09-July-2025 | 100 | 1 | 99 | **99.0%** |
| ChatGPT | English | 09-July-2025 | 100 | 3 | 97 | 97.0% |
| Claude | English | 09-July-2025 | 100 | 3 | 97 | 97.0% |
| ChatGPT | Bahasa Melayu | 09-July-2025 | 100 | 2 | 98 | 98.0% |
| Claude | Bahasa Melayu | 09-July-2025 | 100 | 6 | 94 | 94.0% |

---

